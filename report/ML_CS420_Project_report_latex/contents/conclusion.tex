\section{Conclusion}


\subsection{结果分析}

\begin{enumerate}
    \item 从CNN的曲线当中可以看到，验证集的accuracy会随着训练轮数的增加在某一个epoch突然下降，我们猜想这可能跟模型过拟合有关。
    \item 事实上weight\_decay参数对RNN模型的收敛有很大的影响，只有当weight\_decay设置得足够小，比如低于0.001时，RNN的训练才会收敛。这说明仔细调节超参的重要性。
    \item alexnet和resnet18都是在图像识别领域取得巨大成功的模型，在我们的实验中它们的发挥比sketch-a-net要好很多，这说明即使简笔画不同于一般的照片，良好的CNN模型也是有不错的预测能力。但是与正常图片高达95\%以上的预测准确度相比,这些优异的CNN模型在简笔画上的发挥要低上十个百分点，这说明简笔画这种单单仅有几个线条的卡通图片的确会给分类造成困难。
    \item BiLSTM的结果和AlexNet和ResNet18的结果差不多，但是BiLSTM的训练所耗费的资源更少，在给定笔画的情况下，采用这种方法可能会更好。
    \item CNN+RNN上下两路结合的方法在我们的实验当中取得最佳的预测准确度。这种方法同时兼顾了图片的视觉信息以及笔画的序列信息，通过两种神经网路提取出不同维度的feature，并将这两种feature给结合在一起，使得不同的模型可以学习到数据的不同特征，经过融合后的结果往往能有更好的表现，大有取长补短的意思。
\end{enumerate}
\subsection{未来的改进}
\begin{enumerate}
    \item 我们使用RNN的方法是直接将decoder给剔除，然后在encoder最后添加线性层，这种方法可能没有充分使用笔画的序列信息。或许使用VAE，得到每一种种类简笔画背后的latent space能够对分类有很大的帮助。
    \item CNN模型表现不佳可能是因为简笔画不像一般的图片，简笔画中仅仅只有寥寥数笔，其余是大片的空白，如果能够将这些空白给填充起来，或许CNN就能够发挥出更大的威力。
\end{enumerate}

\subsection{小结}

本项目从 CNN 入手，比较了 AlexNet, ResNet, Sketch-A-Net 对图像信息的分类结果，测试结果是 ResNet 略胜一筹。接着使用 RNN 中的双向 LSTM 对笔画数据进行分类，结果略有提升。最后将两者结合起来，最后通过多层神经网络进行分类，结果进一步有所提升。

CNN 优点在于准确率相对较高，收敛速度快。但缺点就是训练时间较长，从笔画转换为图像数据也需要时间。RNN 优点在于训练速度快，但缺点就在于参数不当的情况下，收敛速度会很慢。将两者结合，可以很好地利用图像的局部信息与笔画的产生顺序，更为高效地获得较好的分类模型。
